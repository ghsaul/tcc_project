{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este trabalho apresenta uma aplicação do modelo BERT na tarefa de classificação de texto.\n",
    "\n",
    "Será analisando o banco de dados X extraído do site Kagle. Este banco possuí duas colunas, uma com o texto da notícia e outra indicando se a notícia é falsa ou não.\n",
    "\n",
    "Utilizaremos neste trabalho a linguagem `Python` (versão 3.11.3), `R` (versão 4.2.1), o software `RStudio` (versão 2023.06.0+421), os pacotes em python `pandas` (versão 2.0.3), `transformers` (versão 4.30.2), `torch` (versão 2.0.1), e os pacotes em R ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importando os pacotes\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statistics import mean\n",
    "from collections import Counter\n",
    "from langdetect import detect, DetectorFactory\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declarando constantes\n",
    "os.environ['CURL_CA_BUNDLE'] = ''  # Caso surja \"[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed\" rode este comando e reduza a versão do pacote requets: \"pip uninstall requests\" e \"pip install requests==2.27.1\"\n",
    "\n",
    "CAMINHO_ORIGINAL = r\"dados\\WELFake_Dataset.csv\"\n",
    "CAMINHO_FINAL = r\"dados\\data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declarando semente aleatória para que este código seja reprodutível\n",
    "my_seed = 288933\n",
    "\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "torch.manual_seed(my_seed)\n",
    "torch.cuda.manual_seed_all(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O banco original possui 3 colunas e 72134 observações, das quais 35028 são notícias verdadeiras (label=0) e 37106 são falsas (label=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 72134 entries, 0 to 72133\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   71576 non-null  object\n",
      " 1   text    72095 non-null  object\n",
      " 2   label   72134 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1                                                NaN   \n",
       "2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "\n",
       "                                                text  label  \n",
       "0  No comment is expected from Barack Obama Membe...      1  \n",
       "1     Did they post their votes for Hillary already?      1  \n",
       "2   Now, most of the demonstrators gathered last ...      1  \n",
       "3  A dozen politically active pastors came here f...      0  \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Importando o banco\n",
    "# df = pd.read_csv(CAMINHO_ORIGINAL, index_col=0)\n",
    "\n",
    "# df.info()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    35028\n",
       "1    37106\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.groupby('label').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de observações removidas por valores nulos nas colunas de título ou de classificação: 558\n"
     ]
    }
   ],
   "source": [
    "# # Renomeando a coluna de título e selecionando somente as colunas de título e de classificação\n",
    "# df.rename({'title': 'titulo'}, axis=1, inplace=True)\n",
    "# df = df[['titulo', 'label']]\n",
    "\n",
    "# n_linhas_antes = len(df)\n",
    "# df = df[~df['titulo'].isnull()]\n",
    "# df = df[~df['label'].isnull()]\n",
    "\n",
    "# n_linhas_depois = len(df)\n",
    "# print(f'Número de observações removidas por valores nulos nas colunas de título ou de classificação: {n_linhas_antes- n_linhas_depois}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de observações removidas por valores duplicados: 9233\n"
     ]
    }
   ],
   "source": [
    "# # Removendo linhas duplicadas\n",
    "# n_linhas_antes = len(df)\n",
    "# df.drop_duplicates(inplace=True)  # Valores de todas as colunas iguais\n",
    "# df.drop_duplicates(subset='titulo', keep=False, inplace=True, ignore_index=True)  # Valores removidos aqui são títulos que possuem ambos os labels\n",
    "\n",
    "# n_linhas_depois = len(df)\n",
    "# print(f'Número de observações removidas por valores duplicados: {n_linhas_antes- n_linhas_depois}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alguns títulos estão em outras línguas além de inglês. Para removê-los, utilizaremos o pacote `langdetect` (versão 1.0.9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786\n",
      "8709\n",
      "17718\n",
      "35080\n",
      "39091\n",
      "40841\n",
      "47261\n",
      "Counter({'en': 60048, 'de': 814, 'fr': 212, 'es': 204, 'ru': 153, 'ca': 152, 'it': 116, 'nl': 96, 'af': 73, 'da': 72, 'no': 68, 'id': 64, 'ro': 50, 'pt': 41, 'et': 27, 'sv': 24, 'tl': 21, 'ar': 19, 'vi': 15, 'lt': 11, 'so': 10, 'tr': 10, 'error': 7, 'hr': 7, 'cy': 6, 'fi': 4, 'pl': 3, 'sl': 3, 'sw': 3, 'bg': 3, 'el': 2, 'lv': 1, 'fa': 1, 'sq': 1, 'zh-cn': 1, 'hu': 1})\n"
     ]
    }
   ],
   "source": [
    "# # Classificando os títulos em línguas\n",
    "# DetectorFactory.seed = 0\n",
    "\n",
    "# lingua = []\n",
    "# for title in df['titulo']:\n",
    "#     try:\n",
    "#         lingua.append(detect(title))\n",
    "#     except:\n",
    "#         lingua.append('error')\n",
    "#         pass\n",
    "\n",
    "# print(Counter(lingua))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos excluir as linhas em que o pacote `langdetect` classificou os títulos como língua russa, árabe, lituana, turca, polonesa, búlgara, grega, chinesa ou títulos que não puderam ser classificados pelo pacote. Vários títulos em inglês foram classificados nas demais línguas, e por tanto consideramos que tal classificação não foi muito acurada. Além disso, é importante ter em mente que vários títulos em línguas que não o inglês não puderam ser removidas do banco de forma automática, o que poderá provocar um ruído no modelo ajustado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de títulos removidos por não estarem em inglês: 209\n"
     ]
    }
   ],
   "source": [
    "# # Removendo títulos em outras línguas\n",
    "# n_linhas_antes = len(df)\n",
    "# df.drop([idx for idx, l in enumerate(lingua) if l in ['ru', 'ar', 'lt', 'tr', 'pl', 'bg', 'el', 'zh-cn', 'error']]\n",
    "#         ,axis=0  # linhas\n",
    "#         ,inplace=True)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# n_linhas_depois = len(df)\n",
    "# print(f'Número de títulos removidos por não estarem em inglês: {n_linhas_antes- n_linhas_depois}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para analisar o tamanho de cada título, vamos considerar o número de tokens do título tokenizado pelo modelo pré-treinado BERT Base. A informação do número máximo de tokens será útil na fase de ajuste do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mínimo de tokens:  3\n",
      "Máximo de tokens:  96\n",
      "Média de tokens:  18.1779\n",
      "Quantidade de tokens por percentil:  [12. 13. 15. 16. 17. 19. 20. 22. 25.]\n",
      "Número de títulos com mais de 128 tokens:  0\n",
      "Número de títulos com mais de 64 tokens:  3\n",
      "Número de títulos com mais de 32 tokens:  1415\n"
     ]
    }
   ],
   "source": [
    "# # Declarando o tokenizador do modelo BERT Base Uncased (que considera todas as letras como minúsculas)\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # Para cada título, calcule o tamanho do vetor de tokens\n",
    "# df['n_token'] = [len(tokenizer.encode(title, add_special_tokens=True)) for title in df['titulo']]\n",
    "\n",
    "# # Analisando algumas estatísticas\n",
    "# print('Mínimo de tokens: ', min(df['n_token']))\n",
    "# print('Máximo de tokens: ', max(df['n_token']))\n",
    "# print('Média de tokens: ', round(mean(df['n_token']), 4))\n",
    "# print('Quantidade de tokens por percentil: ', np.quantile(df['n_token'], q=[.1, .2, .3, .4, .5, .6, .7, .8, .9]))\n",
    "# print('Número de títulos com mais de 128 tokens: ', sum([i > 128 for i in df['n_token']]))\n",
    "# print('Número de títulos com mais de 64 tokens: ', sum([i > 64 for i in df['n_token']]))\n",
    "# print('Número de títulos com mais de 32 tokens: ', sum([i > 32 for i in df['n_token']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 62134 entries, 0 to 62342\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   titulo   62134 non-null  object\n",
      " 1   label    62134 non-null  int64 \n",
      " 2   n_token  62134 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "      <th>label</th>\n",
       "      <th>n_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>About Time! Christian Group Sues Amazon and SP...</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titulo  label  n_token\n",
       "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...      1       35\n",
       "1  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...      1       30\n",
       "2  Bobby Jindal, raised Hindu, uses story of Chri...      0       22\n",
       "3  SATAN 2: Russia unvelis an image of its terrif...      1       25\n",
       "4  About Time! Christian Group Sues Amazon and SP...      1       18"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Banco pré-processado\n",
    "# df.info()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    34404\n",
       "1    27730\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.groupby('label').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O banco final possui 62134 observações, sendo que 55% delas são notícias falsas e 45% notícias verdadeiras, aproximadamente. Com o banco pré-processado pronto, vamos exportá-lo para um arquivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(CAMINHO_FINAL, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estatísticas descritivas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando os dados processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CAMINHO_FINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62134 entries, 0 to 62133\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   titulo   62134 non-null  object\n",
      " 1   label    62134 non-null  int64 \n",
      " 2   n_token  62134 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "      <th>label</th>\n",
       "      <th>n_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>About Time! Christian Group Sues Amazon and SP...</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titulo  label  n_token\n",
       "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...      1       35\n",
       "1  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...      1       30\n",
       "2  Bobby Jindal, raised Hindu, uses story of Chri...      0       22\n",
       "3  SATAN 2: Russia unvelis an image of its terrif...      1       25\n",
       "4  About Time! Christian Group Sues Amazon and SP...      1       18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtendo a distribuição de palavras de cada texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    34404\n",
       "1    27730\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando o modelo BERT pré-treinado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos importar o modelo BERT base, pois não dispomos de capacidade computacional suficiente para rodar o modelo BERT large. Mais especificamente, utilizaremos o modelo BERT base uncased, que não faz diferença entre palavras com letras maiúsculas e minusculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "#model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Change num_labels according to your classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mThis is an example sentence for classification.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39m# Preprocess input text\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode_plus(\u001b[39m'\u001b[39m\u001b[39mtext                  a   q\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m#df['text'][5],\u001b[39;00m\n\u001b[0;32m     18\u001b[0m         add_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     19\u001b[0m         truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     20\u001b[0m         padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m         max_length\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[39mprint\u001b[39m(inputs[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(tokenizer\u001b[39m.\u001b[39mconvert_ids_to_tokens(inputs[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Tokenize and preprocess input text\n",
    "def preprocess_text(text):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=512,  # Adjust according to your input length requirements\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return inputs\n",
    "\n",
    "# Example text for classification\n",
    "text = \"This is an example sentence for classification.\"\n",
    "\n",
    "# Preprocess input text\n",
    "inputs = tokenizer.encode_plus('text                  a   q',#df['text'][5],\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=512)\n",
    "print(inputs['input_ids'])\n",
    "print(tokenizer.convert_ids_to_tokens(inputs['input_ids']))\n",
    "print(len([i for i in inputs['input_ids'] if i != 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>flag</th>\n",
       "      <th>tamanho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the head of a conservative republican faction ...</td>\n",
       "      <td>1</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transgender people will be allowed for the fir...</td>\n",
       "      <td>1</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the special counsel investigation of links bet...</td>\n",
       "      <td>1</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump campaign adviser george papadopoulos tol...</td>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>president donald trump called on the u.s. post...</td>\n",
       "      <td>1</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  flag  tamanho\n",
       "0  the head of a conservative republican faction ...     1      746\n",
       "1  transgender people will be allowed for the fir...     1      396\n",
       "2  the special counsel investigation of links bet...     1      454\n",
       "3  trump campaign adviser george papadopoulos tol...     1      373\n",
       "4  president donald trump called on the u.s. post...     1      849"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
